from django.contrib import messages
from dashboard.models import OllamaSettings
from reNgine.llm.config import LLM_CONFIG
import logging
from markdown import markdown

logger = logging.getLogger(__name__)

def get_default_llm_model():
    """
    Get the default LLM model from database or fallback to default
    Returns the model name as string
    """
    try:
        ollama_settings = OllamaSettings.objects.first()
        if ollama_settings and ollama_settings.selected_model:
            return ollama_settings.selected_model
    except Exception as e:
        logger.error(f"Error while retrieving default LLM model: {e}")
    
    # Fallback to default model from config based on provider
    try:
        if ollama_settings and ollama_settings.use_ollama:
            return LLM_CONFIG['providers']['ollama']['default_model']
        return LLM_CONFIG['providers']['openai']['default_model']
    except Exception as e:
        logger.error(f"Error while getting default model from config: {e}")
        return 'gpt-3.5-turbo'  # Ultimate fallback

def validate_llm_model(request, model_name):
    """Check if LLM model exists and is available"""
    try:
        # Check if model exists in LLMToolkit
        if not LLMToolkit.is_model_available(model_name):
            messages.info(
                request,
                f"Model {model_name} is not available. "
                f'<a href="/llm/settings/">Configure your LLM models here</a>.',
                extra_tags='safe'
            )
            return False
        return True
    except Exception as e:
        logger.error(f"Error while validating LLM model: {e}")
        return False 
    
def get_llm_vuln_input_description(title, path):
	vulnerability_description = ''
	vulnerability_description += f'Vulnerability Title: {title}'
	# llm gives concise vulnerability description when a vulnerable URL is provided
	vulnerability_description += f'\nVulnerable URL: {path}'

	return vulnerability_description

def convert_markdown_to_html(markdown_text):
    if markdown_text is None:
        return ""
    
    # Extract LLM badge if present (at the beginning of the text)
    llm_badge = ""
    if markdown_text.startswith('[LLM:'):
        llm_name = markdown_text[5:markdown_text.index(']')]
        llm_badge = f'<span class="badge bg-soft-primary text-primary mb-3">Generated by {llm_name}</span><br>'
        markdown_text = markdown_text[markdown_text.index(']')+1:].strip()
    
    # Configure Markdown with specific options
    html_content = markdown(markdown_text,
        extensions=[
            'fenced_code',
            'tables',
            'nl2br',
            'sane_lists',    # Better list handling
            'def_list',      # Definition lists support
        ],
    )

    # Add Bootstrap classes and clean up formatting
    html_content = (html_content
        .replace('<pre><code>', '<pre class="bg-light p-3 rounded"><code class="text-danger">')
        .replace('<ul>', '<ul class="list-unstyled">')
        .replace('<ol>', '<ul class="list-unstyled">')  # Convert ordered lists to unordered
        .replace('</ol>', '</ul>')
        .replace('\n\n', '<br>')
        .replace('\n', '')
    )
    
    return llm_badge + html_content
